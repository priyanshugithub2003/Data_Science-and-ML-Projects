{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb07b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4ba6c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfa66bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/priyanshugithub2003/Datasets_Data_Science/main/pima-indians-diabetes-2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe0aa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preg</th>\n",
       "      <th>Plas</th>\n",
       "      <th>Pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>3</td>\n",
       "      <td>174</td>\n",
       "      <td>58</td>\n",
       "      <td>22</td>\n",
       "      <td>194</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.593</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>66</td>\n",
       "      <td>36</td>\n",
       "      <td>200</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.289</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "      <td>86</td>\n",
       "      <td>17</td>\n",
       "      <td>105</td>\n",
       "      <td>29.3</td>\n",
       "      <td>0.695</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6</td>\n",
       "      <td>144</td>\n",
       "      <td>72</td>\n",
       "      <td>27</td>\n",
       "      <td>228</td>\n",
       "      <td>33.9</td>\n",
       "      <td>0.255</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>4</td>\n",
       "      <td>171</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43.6</td>\n",
       "      <td>0.479</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>58</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0.551</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>4</td>\n",
       "      <td>125</td>\n",
       "      <td>70</td>\n",
       "      <td>18</td>\n",
       "      <td>122</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.144</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>10</td>\n",
       "      <td>108</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.272</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>9</td>\n",
       "      <td>156</td>\n",
       "      <td>86</td>\n",
       "      <td>28</td>\n",
       "      <td>155</td>\n",
       "      <td>34.3</td>\n",
       "      <td>1.189</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>185</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.682</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Preg  Plas  Pres  skin  test  mass   pedi  age  class\n",
       "611     3   174    58    22   194  32.9  0.593   36      1\n",
       "721     1   114    66    36   200  38.1  0.289   21      0\n",
       "640     0   102    86    17   105  29.3  0.695   27      0\n",
       "95      6   144    72    27   228  33.9  0.255   40      0\n",
       "235     4   171    72     0     0  43.6  0.479   26      1\n",
       "671     1    99    58    10     0  25.4  0.551   21      0\n",
       "493     4   125    70    18   122  28.9  1.144   45      1\n",
       "143    10   108    66     0     0  32.4  0.272   42      1\n",
       "152     9   156    86    28   155  34.3  1.189   42      1\n",
       "595     0   188    82    14   185  32.0  0.682   22      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e17450f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Preg     0\n",
       "Plas     0\n",
       "Pres     0\n",
       "skin     0\n",
       "test     0\n",
       "mass     0\n",
       "pedi     0\n",
       "age      0\n",
       "class    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a04f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Preg    768 non-null    int64  \n",
      " 1   Plas    768 non-null    int64  \n",
      " 2   Pres    768 non-null    int64  \n",
      " 3   skin    768 non-null    int64  \n",
      " 4   test    768 non-null    int64  \n",
      " 5   mass    768 non-null    float64\n",
      " 6   pedi    768 non-null    float64\n",
      " 7   age     768 non-null    int64  \n",
      " 8   class   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c29c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we can see no missing values are found but remember\n",
    "# sometimes missing values are represented by 0 also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13549fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Plas'].replace(0,np.nan,inplace=True)\n",
    "df['Pres'].replace(0,np.nan,inplace=True)\n",
    "df['skin'].replace(0,np.nan,inplace=True)\n",
    "df['test'].replace(0,np.nan,inplace=True)\n",
    "df['mass'].replace(0,np.nan,inplace=True)\n",
    "df['pedi'].replace(0,np.nan,inplace=True)\n",
    "df['age'].replace(0,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a01a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "medianfiller=lambda x:x.fillna(x.median())\n",
    "df=df.apply(medianfiller,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e64489a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#median1=df['skin'].median()\n",
    "#median1\n",
    "#median2=df['Pres'].median()\n",
    "#median3=df['test'].median()\n",
    "#median4=df['mass'].median()\n",
    "#median5=df['pedi'].median()\n",
    "#median6=df['age'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f587aed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preg</th>\n",
       "      <th>Plas</th>\n",
       "      <th>Pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>5</td>\n",
       "      <td>106.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>39.5</td>\n",
       "      <td>0.286</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>10</td>\n",
       "      <td>115.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0.261</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10</td>\n",
       "      <td>125.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>31.1</td>\n",
       "      <td>0.205</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>59.4</td>\n",
       "      <td>2.420</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>115.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.529</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>5</td>\n",
       "      <td>158.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>29.8</td>\n",
       "      <td>0.207</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>4</td>\n",
       "      <td>132.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.302</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>3</td>\n",
       "      <td>82.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.389</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>1</td>\n",
       "      <td>128.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>1.057</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>10</td>\n",
       "      <td>133.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.245</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Preg   Plas  Pres  skin   test  mass   pedi  age  class\n",
       "141     5  106.0  82.0  30.0  125.0  39.5  0.286   38      0\n",
       "706    10  115.0  72.0  29.0  125.0  32.3  0.261   30      1\n",
       "25     10  125.0  70.0  26.0  115.0  31.1  0.205   41      1\n",
       "445     0  180.0  78.0  63.0   14.0  59.4  2.420   25      1\n",
       "19      1  115.0  70.0  30.0   96.0  34.6  0.529   32      1\n",
       "361     5  158.0  70.0  29.0  125.0  29.8  0.207   63      0\n",
       "535     4  132.0  72.0  29.0  125.0  32.9  0.302   23      1\n",
       "398     3   82.0  70.0  29.0  125.0  21.1  0.389   25      0\n",
       "755     1  128.0  88.0  39.0  110.0  36.5  1.057   37      1\n",
       "578    10  133.0  68.0  29.0  125.0  27.0  0.245   36      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2058f4",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "047921af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['class'],axis=1)\n",
    "Y=df[['class']]#creates a DataFrame\n",
    "Z=df['class'] #creates a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f021cecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class\n",
       "1        0\n",
       "750      1\n",
       "463      0\n",
       "368      0\n",
       "570      0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c89b74f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "442    0\n",
       "268    0\n",
       "548    0\n",
       "273    0\n",
       "657    0\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1626de20",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8a6c1d",
   "metadata": {},
   "source": [
    "## Fit Linear Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c06b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model=LogisticRegression()\n",
    "reg_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5368110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7690875232774674"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f533bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7748917748917749"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c00c74",
   "metadata": {},
   "source": [
    "# Very Helpful code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9829ca67",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\",None)\n",
    "# to display all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b744ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\",None)\n",
    "# to display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f567fa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preg</th>\n",
       "      <th>Plas</th>\n",
       "      <th>Pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>4</td>\n",
       "      <td>96.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>3</td>\n",
       "      <td>158.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>387.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.295</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>8</td>\n",
       "      <td>85.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.136</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>4</td>\n",
       "      <td>189.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.680</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>1</td>\n",
       "      <td>96.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.289</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>5</td>\n",
       "      <td>187.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>43.6</td>\n",
       "      <td>1.034</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>0.453</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>9</td>\n",
       "      <td>123.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.374</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>29.6</td>\n",
       "      <td>0.709</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>0.572</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.292</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>4</td>\n",
       "      <td>94.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.148</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>119.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>28.5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.270</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>0.455</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1</td>\n",
       "      <td>90.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>24.5</td>\n",
       "      <td>1.138</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>11</td>\n",
       "      <td>135.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>52.3</td>\n",
       "      <td>0.578</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>9</td>\n",
       "      <td>72.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.280</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>3</td>\n",
       "      <td>89.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.551</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5</td>\n",
       "      <td>124.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.220</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5</td>\n",
       "      <td>158.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.395</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>46.3</td>\n",
       "      <td>1.096</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>10</td>\n",
       "      <td>129.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>41.2</td>\n",
       "      <td>0.441</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0.545</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>40.6</td>\n",
       "      <td>0.284</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>6</td>\n",
       "      <td>125.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.464</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>2</td>\n",
       "      <td>157.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>440.0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.134</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>0.399</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>29.2</td>\n",
       "      <td>0.192</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>8</td>\n",
       "      <td>194.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.551</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.813</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.966</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>2</td>\n",
       "      <td>129.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.304</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>5</td>\n",
       "      <td>85.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.224</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>4</td>\n",
       "      <td>99.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.294</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>1</td>\n",
       "      <td>122.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.692</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>59.4</td>\n",
       "      <td>2.420</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>0.630</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.510</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>8</td>\n",
       "      <td>179.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.719</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>5</td>\n",
       "      <td>139.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.411</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>6</td>\n",
       "      <td>162.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.178</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.637</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>10</td>\n",
       "      <td>68.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.285</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.234</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0.192</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>1</td>\n",
       "      <td>114.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>38.1</td>\n",
       "      <td>0.289</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>3</td>\n",
       "      <td>173.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.970</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>6</td>\n",
       "      <td>103.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>24.3</td>\n",
       "      <td>0.249</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>3</td>\n",
       "      <td>111.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.142</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>10</td>\n",
       "      <td>161.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>25.5</td>\n",
       "      <td>0.326</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>0.334</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2</td>\n",
       "      <td>155.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.433</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>5</td>\n",
       "      <td>139.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.361</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.735</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>42.6</td>\n",
       "      <td>0.431</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.515</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>3</td>\n",
       "      <td>163.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.268</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>9</td>\n",
       "      <td>140.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.734</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>3</td>\n",
       "      <td>96.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.944</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>45.3</td>\n",
       "      <td>0.686</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>37.7</td>\n",
       "      <td>0.362</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.600</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.207</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.254</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>4</td>\n",
       "      <td>145.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>32.5</td>\n",
       "      <td>0.235</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>2</td>\n",
       "      <td>174.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>0.646</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.252</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.527</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>11</td>\n",
       "      <td>155.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>1.353</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.268</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>32.1</td>\n",
       "      <td>0.612</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.725</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>7</td>\n",
       "      <td>97.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>40.9</td>\n",
       "      <td>0.871</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>8</td>\n",
       "      <td>120.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.409</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.391</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.833</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>7</td>\n",
       "      <td>129.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.439</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0.647</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>8</td>\n",
       "      <td>126.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.9</td>\n",
       "      <td>0.162</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>4</td>\n",
       "      <td>141.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>27.6</td>\n",
       "      <td>0.244</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.874</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>1</td>\n",
       "      <td>111.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.138</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.444</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>11</td>\n",
       "      <td>138.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>0.420</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.731</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>10</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.825</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.660</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>7</td>\n",
       "      <td>114.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>27.4</td>\n",
       "      <td>0.732</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0.243</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1</td>\n",
       "      <td>147.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>49.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>97.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.147</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>7</td>\n",
       "      <td>94.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.738</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>3</td>\n",
       "      <td>112.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.197</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>8</td>\n",
       "      <td>143.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>0.129</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Preg   Plas   Pres  skin   test  mass   pedi  age  class\n",
       "288     4   96.0   56.0  17.0   49.0  20.8  0.340   26      0\n",
       "710     3  158.0   64.0  13.0  387.0  31.2  0.295   24      0\n",
       "194     8   85.0   55.0  20.0  125.0  24.4  0.136   42      0\n",
       "549     4  189.0  110.0  31.0  125.0  28.5  0.680   37      0\n",
       "9       8  125.0   96.0  29.0  125.0  32.3  0.232   54      1\n",
       "208     1   96.0   64.0  27.0   87.0  33.2  0.289   21      0\n",
       "546     5  187.0   76.0  27.0  207.0  43.6  1.034   53      1\n",
       "738     2   99.0   60.0  17.0  160.0  36.6  0.453   21      0\n",
       "191     9  123.0   70.0  44.0   94.0  33.1  0.374   40      0\n",
       "167     4  120.0   68.0  29.0  125.0  29.6  0.709   34      0\n",
       "145     0  102.0   75.0  23.0  125.0  32.3  0.572   21      0\n",
       "610     3  106.0   54.0  21.0  158.0  30.9  0.292   24      0\n",
       "629     4   94.0   65.0  22.0  125.0  24.7  0.148   21      0\n",
       "23      9  119.0   80.0  35.0  125.0  29.0  0.263   29      1\n",
       "742     1  109.0   58.0  18.0  116.0  28.5  0.219   22      0\n",
       "608     0  152.0   82.0  39.0  272.0  41.5  0.270   27      0\n",
       "647     0  179.0   50.0  36.0  159.0  37.8  0.455   22      1\n",
       "434     1   90.0   68.0   8.0  125.0  24.5  1.138   36      0\n",
       "193    11  135.0   72.0  29.0  125.0  52.3  0.578   40      1\n",
       "403     9   72.0   78.0  25.0  125.0  31.6  0.280   38      0\n",
       "431     3   89.0   74.0  16.0   85.0  30.4  0.551   38      0\n",
       "763    10  101.0   76.0  48.0  180.0  32.9  0.171   63      0\n",
       "116     5  124.0   74.0  29.0  125.0  34.0  0.220   38      1\n",
       "195     5  158.0   84.0  41.0  210.0  39.4  0.395   29      1\n",
       "747     1   81.0   74.0  41.0   57.0  46.3  1.096   32      0\n",
       "712    10  129.0   62.0  36.0  125.0  41.2  0.441   38      1\n",
       "372     0   84.0   64.0  22.0   66.0  35.8  0.545   21      0\n",
       "428     0  135.0   94.0  46.0  145.0  40.6  0.284   26      0\n",
       "217     6  125.0   68.0  30.0  120.0  30.0  0.464   32      0\n",
       "645     2  157.0   74.0  35.0  440.0  39.4  0.134   30      0\n",
       "150     1  136.0   74.0  50.0  204.0  37.4  0.399   24      0\n",
       "240     1   91.0   64.0  24.0  125.0  29.2  0.192   21      0\n",
       "767     1   93.0   70.0  31.0  125.0  30.4  0.315   23      0\n",
       "489     8  194.0   80.0  29.0  125.0  26.1  0.551   67      0\n",
       "576     6  108.0   44.0  20.0  130.0  24.0  0.813   35      0\n",
       "35      4  103.0   60.0  33.0  192.0  24.0  0.966   33      0\n",
       "703     2  129.0   72.0  29.0  125.0  38.5  0.304   41      0\n",
       "218     5   85.0   74.0  22.0  125.0  29.0  1.224   32      1\n",
       "488     4   99.0   72.0  17.0  125.0  25.6  0.294   28      0\n",
       "326     1  122.0   64.0  32.0  156.0  35.1  0.692   30      1\n",
       "445     0  180.0   78.0  63.0   14.0  59.4  2.420   25      1\n",
       "484     0  145.0   72.0  29.0  125.0  44.2  0.630   31      1\n",
       "448     0  104.0   64.0  37.0   64.0  33.6  0.510   22      1\n",
       "175     8  179.0   72.0  42.0  130.0  32.7  0.719   36      1\n",
       "71      5  139.0   64.0  35.0  140.0  28.6  0.411   26      0\n",
       "749     6  162.0   62.0  29.0  125.0  24.3  0.178   50      1\n",
       "156     2   99.0   52.0  15.0   94.0  24.6  0.637   21      0\n",
       "672    10   68.0  106.0  23.0   49.0  35.5  0.285   47      0\n",
       "650     1   91.0   54.0  25.0  100.0  25.2  0.234   23      0\n",
       "112     1   89.0   76.0  34.0   37.0  31.2  0.192   23      0\n",
       "721     1  114.0   66.0  36.0  200.0  38.1  0.289   21      0\n",
       "716     3  173.0   78.0  39.0  185.0  33.8  0.970   31      1\n",
       "587     6  103.0   66.0  29.0  125.0  24.3  0.249   29      0\n",
       "190     3  111.0   62.0  29.0  125.0  22.6  0.142   21      0\n",
       "306    10  161.0   68.0  23.0  132.0  25.5  0.326   47      1\n",
       "280     0  146.0   70.0  29.0  125.0  37.9  0.334   28      1\n",
       "312     2  155.0   74.0  17.0   96.0  26.6  0.433   27      1\n",
       "189     5  139.0   80.0  35.0  160.0  31.6  0.361   25      1\n",
       "537     0   57.0   60.0  29.0  125.0  21.7  0.735   67      0\n",
       "213     0  140.0   65.0  26.0  130.0  42.6  0.431   24      1\n",
       "736     0  126.0   86.0  27.0  120.0  27.4  0.515   21      0\n",
       "515     3  163.0   70.0  18.0  105.0  31.6  0.268   28      1\n",
       "743     9  140.0   94.0  29.0  125.0  32.7  0.734   45      1\n",
       "396     3   96.0   56.0  34.0  115.0  24.7  0.944   39      0\n",
       "531     0  107.0   76.0  29.0  125.0  45.3  0.686   24      0\n",
       "625     4   90.0   88.0  47.0   54.0  37.7  0.362   29      0\n",
       "467     0   97.0   64.0  36.0  100.0  36.8  0.600   25      0\n",
       "615     3  106.0   72.0  29.0  125.0  25.8  0.207   27      0\n",
       "764     2  122.0   70.0  27.0  125.0  36.8  0.340   27      0\n",
       "322     0  124.0   70.0  20.0  125.0  27.4  0.254   36      1\n",
       "666     4  145.0   82.0  18.0  125.0  32.5  0.235   70      1\n",
       "732     2  174.0   88.0  37.0  120.0  44.5  0.646   24      1\n",
       "367     0  101.0   64.0  17.0  125.0  21.0  0.252   21      0\n",
       "432     1   80.0   74.0  11.0   60.0  30.0  0.527   22      0\n",
       "259    11  155.0   76.0  28.0  150.0  33.3  1.353   51      1\n",
       "140     3  128.0   78.0  29.0  125.0  21.1  0.268   55      0\n",
       "262     4   95.0   70.0  32.0  125.0  32.1  0.612   24      0\n",
       "181     0  119.0   64.0  18.0   92.0  34.9  0.725   23      0\n",
       "638     7   97.0   76.0  32.0   91.0  40.9  0.871   32      1\n",
       "509     8  120.0   78.0  29.0  125.0  25.0  0.409   64      0\n",
       "76      7   62.0   78.0  29.0  125.0  32.6  0.391   41      0\n",
       "157     1  109.0   56.0  21.0  135.0  25.2  0.833   23      0\n",
       "693     7  129.0   68.0  49.0  125.0  38.5  0.439   43      1\n",
       "134     2   96.0   68.0  13.0   49.0  21.1  0.647   26      0\n",
       "478     8  126.0   74.0  38.0   75.0  25.9  0.162   39      0\n",
       "184     4  141.0   74.0  29.0  125.0  27.6  0.244   40      0\n",
       "200     0  113.0   80.0  16.0  125.0  31.0  0.874   21      0\n",
       "609     1  111.0   62.0  13.0  182.0  24.0  0.138   23      0\n",
       "390     1  100.0   66.0  29.0  196.0  32.0  0.444   42      0\n",
       "36     11  138.0   76.0  29.0  125.0  33.2  0.420   35      0\n",
       "371     0  118.0   64.0  23.0   89.0  32.3  1.731   21      0\n",
       "542    10   90.0   85.0  32.0  125.0  34.9  0.825   56      1\n",
       "529     0  111.0   65.0  29.0  125.0  24.6  0.660   31      0\n",
       "630     7  114.0   64.0  29.0  125.0  27.4  0.732   34      1\n",
       "352     3   61.0   82.0  28.0  125.0  34.4  0.243   46      0\n",
       "746     1  147.0   94.0  41.0  125.0  49.3  0.358   27      1\n",
       "438     1   97.0   70.0  15.0  125.0  18.2  0.147   21      0\n",
       "503     7   94.0   64.0  25.0   79.0  33.3  0.738   41      0\n",
       "321     3  112.0   74.0  30.0  125.0  31.6  0.197   25      1\n",
       "586     8  143.0   66.0  29.0  125.0  34.9  0.129   41      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "106e8183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=reg_model.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbfd74ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7748917748917749"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7902905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83       146\n",
      "           1       0.76      0.56      0.65        85\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.77      0.73      0.74       231\n",
      "weighted avg       0.77      0.77      0.77       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d48de8d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGsCAYAAADDvZ3KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAoKklEQVR4nO3de3RU5dn+8WskyZCEEE4yk9QAoaQeACUCUoJyKBClKPBaBYQiLLFCQUuMCKaWg6eMgRbSglDxBCqI9uUg9QdKQAQxqBAES0ARiSCHMfiSJhzCJDD794fL0YEAGRgyecL307XXMnvv2fPMrDX29r6eZ2+bZVmWAAAADHJFqAcAAAAQKAoYAABgHAoYAABgHAoYAABgHAoYAABgHAoYAABgHAoYAABgHAoYAABgnLBQD+BHY5oNDPUQgBpt56niUA8BqNFWfLuiyt6r/PvdQbtWeKPmQbtWVaIDAwAAjFNtOjAAAKCSvKdCPYKQo4ABAMA0ljfUIwg5IiQAAGAcOjAAAJjGSweGAgYAAMNYREhESAAAwDx0YAAAMA0REgUMAADGIUIiQgIAAOahAwMAgGm4kR0FDAAAxiFCIkICAADmoQMDAIBpWIVEAQMAgGm4kR0REgAAMBAdGAAATEOERAEDAIBxiJCIkAAAgHnowAAAYBpuZEcBAwCAcYiQiJAAAIB56MAAAGAaViFRwAAAYBwiJCIkAABgHjowAACYhgiJAgYAANNYFsuoiZAAAIBx6MAAAGAaJvFSwAAAYBzmwBAhAQAA89CBAQDANERIdGAAADCO91TwtgCsW7dOd9xxh+Lj42Wz2bR06VLfsfLyco0fP16tW7dWdHS04uPjde+99+rAgQN+1/B4PHrooYfUqFEjRUdHq0+fPtq3b1/AXwEFDAAAqJRjx47phhtu0MyZM884dvz4cW3evFkTJkzQ5s2btXjxYu3cuVN9+vTxOy8tLU1LlizRwoULtX79eh09elS33367Tp0KrJgiQgIAwDQhipB69eqlXr16VXgsNjZWOTk5fvtmzJihm266SXv37lWTJk1UXFysl156Sa+99pp69OghSXr99deVkJCgVatW6dZbb630WOjAAABgGq83aJvH41FJSYnf5vF4gjLM4uJi2Ww21atXT5KUl5en8vJypaam+s6Jj49Xq1atlJubG9C1KWAAALiMuVwuxcbG+m0ul+uir3vixAk99thjGjRokOrWrStJcrvdioiIUP369f3OdTgccrvdAV2fCAkAANMEMULKyMhQenq63z673X5R1ywvL9fAgQPl9Xo1a9as855vWZZsNltA70EBAwCAaYJ4Izu73X7RBcvPlZeXq3///iooKND777/v675IktPpVFlZmYqKivy6MIWFhUpJSQnofYiQAABAUPxYvHz11VdatWqVGjZs6He8bdu2Cg8P95vse/DgQW3bti3gAoYODAAApgnRowSOHj2qXbt2+f4uKCjQli1b1KBBA8XHx+uuu+7S5s2b9c477+jUqVO+eS0NGjRQRESEYmNjNXz4cD3yyCNq2LChGjRooLFjx6p169a+VUmVRQEDAIBhLCuwe6YEy6ZNm9StWzff3z/OnRk6dKgmT56sZcuWSZLatGnj97o1a9aoa9eukqTp06crLCxM/fv3V2lpqbp37665c+eqVq1aAY3FZlmWdeEfJXjGNBsY6iEANdrOU8WhHgJQo634dkWVvVfpurlBu1Zk52FBu1ZVogMDAIBpeBo1BQwAAMbhYY6sQgIAAOahAwMAgGmIkChgAAAwDhESERIAADAPHRgAAExDhEQBAwCAcYiQiJAAAIB56MAAAGAaIiQKGAAAjEMBQ4QEAADMQwcGAADTMImXAgYAAOMQIREhAQAA89CBAQDANERIFDAAABiHCIkICQAAmIcODAAApiFCooABAMA4REhESAAAwDx0YAAAMA0dGAoYAACMY1mhHkHIESEBAADj0IEBAMA0REgUMAAAGIcChggJAACYhw4MAACm4UZ2FDAAABiHCIkICQAAmIcODAAApuE+MBQwAAAYhwiJCAkAAJiHDgwAAKahA0MBAwCAcVhGTYQEAADMQwcGAADDWF5WIVHAAABgGubAECEBAADz0IEBAMA0TOKlgAEAwDjMgSFCAgAA5qEDAwCAaZjESwcGAACYhw4MAACmoQNDAQMAgHEsJvESIQEAAOPQgUGl9BjVV3eMu0cfvLxcS558VZIUEWXXHeMH6frUdoqqH6PD+w5p3dx39dHrOSEeLVD99R7SW72H9JbjKockac/OPVqQvUCbPtgkSVrx7YoKX/fi0y9q0fOLqmycqKaIkChgcH5Nrm+ulHu6a/+OPX77/2fCvUrq2FKvPfycDu87pKtvuV53P3Wfir87rG05eSEaLWCG7w9+r1dcr+jANwckST3u7qGJL03Ug70e1N6dezXoxkF+57fr1k5pU9P00YqPQjFcVDfcB4YICecWEWXXkOyHtPCxOTpefMzvWOKNv9Kni9Zp18fbdXjfIW14Y7UO7NijJq1/GaLRAub4ZNUn2rhmo/YX7Nf+gv2aN2WeThw/oWuSr5EkFR0q8tt+nfprfZ77udx73SEeOVA9UMDgnO5+6j5tX/OZdn607Yxjuzd9odY92irWUV+S1KLjdboyMU5frNta1cMEjHbFFVeoS58uqh1ZW19s/uKM4/Ua1dNNv7lJ7735XghGh2rJ8gZvMxQREs4q+Y6OSmjVXH/t8+cKjy+aPFcDn31AT34yW6fKT8ryWnrjsTnavenLKh4pYKZm1zTTtKXTFGGPUOmxUj31h6e096u9Z5zX464eKj1WSnyEnxAhBb+A+fbbbzVp0iS9/PLLZz3H4/HI4/H47TtpnVKYrVawh4MLVC+uoX43cahm3Zupk57yCs/pPKyXmrZJ0pzhU1S0/3v98qZrdfdT96mksKjCjg0Af/u+3qfRt41Wnbp11KlXJz0y/RGNu3vcGUVM6oBUrVmyRuVn+S0Cl6OgR0iHDx/WvHnzznmOy+VSbGys37apeEewh4KLkNA6UTFX1tPYf7s0bdd8Tds1X0m/vk6dh92mabvmKyLSrtsfHailT7+m/NWbdeCLvfrw1ff02Tsb9JsHbg/18AEjnCw/qYPfHNRXn3+luVlztXv7bvW9r6/fOS1vaqmEFgl69413QzRKVEeW1xu0zVQBd2CWLVt2zuO7d+8+7zUyMjKUnp7uv6/18ECHgkto50fb9GzqWL99g6b+Ud99fUCr//m2bLWuUFhEmKzTbqbk9XplszG1CrgQNptN4fZwv323DrxVOz/fqYIdBSEaFaolIqTAC5h+/frJZrOd8X9cP2ez2c55DbvdLrvd7j8Q4qNqxXPshA7u3Oe/r9SjY/894tv/1cfb1TdjsMpPlOnwvkNq8evr1P7Ozlr69GuhGDJglKHjh2rTmk06dOCQoupEqUufLmrdsbUmDJngOyeqTpRu6X2LXnjqhRCOFPjJunXrNHXqVOXl5engwYNasmSJ+vXr5ztuWZaeeOIJzZkzR0VFRerQoYOee+45tWzZ0neOx+PR2LFj9cYbb6i0tFTdu3fXrFmzdNVVVwU0loD/UzkuLk6LFi2S1+utcNu8eXOgl4Sh5j30d+39/GsNyX5QGav+ph5/7KP/N3UhN7IDKqF+o/p6NPtRvfjBi3K94dLVba7WhCET9NmHn/nO6dKni2STPnj7g9ANFNVTiFYhHTt2TDfccINmzpxZ4fEpU6Zo2rRpmjlzpjZu3Cin06mePXvqyJEjvnPS0tK0ZMkSLVy4UOvXr9fRo0d1++2369SpUwGNxWadq5VSgT59+qhNmzZ68sknKzy+detWJScnyxtgrjam2cCAzgcQmJ2nikM9BKBGO9vdky+FY08ODtq1oifOv6DX2Ww2vw6MZVmKj49XWlqaxo8fL+mHbovD4VBWVpZGjBih4uJiXXnllXrttdc0YMAASdKBAweUkJCg5cuX69Zbb630+wfcgXn00UeVkpJy1uMtWrTQmjVrAr0sAAAIAY/Ho5KSEr/t9JXClVFQUCC3263U1FTfPrvdri5duig3N1eSlJeXp/Lycr9z4uPj1apVK985lRVwAXPLLbfotttuO+vx6OhodenSJdDLAgCAyvJ6g7ZVtDLY5XIFPCS3+4e7RDscDr/9DofDd8ztdisiIkL169c/6zmVxY3sAAAwTRBXIWU8fubK4NMX2gTi9IU8lmWdd3FPZc45HetdAQC4jNntdtWtW9dvu5ACxul0StIZnZTCwkJfV8bpdKqsrExFRUVnPaeyKGAAADBNNXwWUmJiopxOp3JyflqJWlZWprVr1/rmzrZt21bh4eF+5xw8eFDbtm075/zaihAhAQBgmhDdyO7o0aPatWuX7++CggJt2bJFDRo0UJMmTZSWlqbMzEwlJSUpKSlJmZmZioqK0qBBgyRJsbGxGj58uB555BE1bNhQDRo00NixY9W6dWv16NEjoLFQwAAAgErZtGmTunXr5vv7x7kzQ4cO1dy5czVu3DiVlpZq1KhRvhvZrVy5UjExMb7XTJ8+XWFhYerfv7/vRnZz585VrVqB3dA24PvAXCrcBwa4tLgPDHBpVeV9YI5m/C5o16rjWhS0a1UlOjAAAJiGZyExiRcAAJiHDgwAAKahA0MBAwCAcYK4/NlUREgAAMA4dGAAADANERIFDAAAprEoYIiQAACAeejAAABgGjowFDAAABjHyyokIiQAAGAcOjAAAJiGCIkCBgAA41DAECEBAADz0IEBAMAwlkUHhgIGAADTECERIQEAAPPQgQEAwDR0YChgAAAwDc9CIkICAAAGogMDAIBp6MBQwAAAYBwehUSEBAAAzEMHBgAAwzCJlwIGAADzUMAQIQEAAPPQgQEAwDRM4qWAAQDANMyBIUICAAAGogMDAIBpiJAoYAAAMA0REhESAAAwEB0YAABMQ4REAQMAgGksChgiJAAAYB46MAAAmIYODAUMAACmIUIiQgIAAAaiAwMAgGnowFDAAABgGiIkIiQAAGAgOjAAABiGDgwFDAAAxqGAIUICAAAGogMDAIBpLFuoRxByFDAAABiGCIkICQAAGIgODAAAhrG8REgUMAAAGIYIiQgJAAAYiA4MAACGsViFRAEDAIBpiJCIkAAAgIHowAAAYBhWIVHAAABgHMsK9QhCjwgJAAAYhwIGAADDWF5b0LZAnDx5Un/5y1+UmJioyMhINW/eXE8++aS83p9mFVuWpcmTJys+Pl6RkZHq2rWr8vPzg/0VUMAAAGCaUBUwWVlZ+uc//6mZM2dqx44dmjJliqZOnaoZM2b4zpkyZYqmTZummTNnauPGjXI6nerZs6eOHDkS1O+AAgYAAFTKhg0b1LdvX/Xu3VvNmjXTXXfdpdTUVG3atEnSD92X7OxsPf7447rzzjvVqlUrzZs3T8ePH9eCBQuCOhYKGAAADGNZwds8Ho9KSkr8No/HU+H73nzzzVq9erV27twpSdq6davWr1+v3/72t5KkgoICud1upaam+l5jt9vVpUsX5ebmBvU7oIABAMAwwYyQXC6XYmNj/TaXy1Xh+44fP1733HOPrrnmGoWHhys5OVlpaWm65557JElut1uS5HA4/F7ncDh8x4KFZdQAAFzGMjIylJ6e7rfPbrdXeO6bb76p119/XQsWLFDLli21ZcsWpaWlKT4+XkOHDvWdZ7P5z62xLOuMfReLAgYAAMME81lIdrv9rAXL6R599FE99thjGjhwoCSpdevW2rNnj1wul4YOHSqn0ynph05MXFyc73WFhYVndGUuFhESAACGsbzB2wJx/PhxXXGFf+lQq1Yt3zLqxMREOZ1O5eTk+I6XlZVp7dq1SklJuejP/XN0YAAAQKXccccdeuaZZ9SkSRO1bNlSn332maZNm6b77rtP0g/RUVpamjIzM5WUlKSkpCRlZmYqKipKgwYNCupYKGAAADCMN4gRUiBmzJihCRMmaNSoUSosLFR8fLxGjBihiRMn+s4ZN26cSktLNWrUKBUVFalDhw5auXKlYmJigjoWm2VVjycqjGk2MNRDAGq0naeKQz0EoEZb8e2KKnuvL6/pFbRrXf1F1Y07mJgDAwAAjEOEBACAYQJ9BEBNRAEDAIBhqsfkj9AiQgIAAMahAwMAgGGIkChgAAAwTqiWUVcnREgAAMA4dGAAADBMMJ+FZCoKGAAADMMqJCIkAABgIDowAAAYhkm8FDAAABiHOTBESAAAwEB0YAAAMAyTeClgAAAwDnNgiJAAAICBqk0H5rkDH4Z6CECNVspvDKgxmMRbjQoYAABQOURIREgAAMBAdGAAADAMi5AoYAAAMA4REhESAAAwEB0YAAAMwyokChgAAIzjDfUAqgEiJAAAYBw6MAAAGMYSERIFDAAAhvGyjpoICQAAmIcODAAAhvESIVHAAABgGubAECEBAAAD0YEBAMAw3AeGAgYAAOMQIREhAQAAA9GBAQDAMERIFDAAABiHAoYICQAAGIgODAAAhmESLwUMAADG8VK/ECEBAADz0IEBAMAwPAuJAgYAAONYoR5ANUCEBAAAjEMHBgAAw3AfGAoYAACM47UxB4YICQAAGIcODAAAhmESLwUMAADGYQ4MERIAADAQHRgAAAzDowQoYAAAMA534iVCAgAABqIDAwCAYViFRAEDAIBxmANDhAQAAAxEAQMAgGG8QdwCtX//fv3+979Xw4YNFRUVpTZt2igvL8933LIsTZ48WfHx8YqMjFTXrl2Vn59/oR/1rChgAAAwjBXELRBFRUXq1KmTwsPDtWLFCm3fvl1/+9vfVK9ePd85U6ZM0bRp0zRz5kxt3LhRTqdTPXv21JEjRy7iE5+JOTAAAKBSsrKylJCQoFdeecW3r1mzZr5/tixL2dnZevzxx3XnnXdKkubNmyeHw6EFCxZoxIgRQRsLHRgAAAzjtQVv83g8Kikp8ds8Hk+F77ts2TK1a9dOd999txo3bqzk5GS98MILvuMFBQVyu91KTU317bPb7erSpYtyc3OD+h1QwAAAYJhgzoFxuVyKjY3121wuV4Xvu3v3bs2ePVtJSUl67733NHLkSP3pT3/Sq6++Kklyu92SJIfD4fc6h8PhOxYsREgAAFzGMjIylJ6e7rfPbrdXeK7X61W7du2UmZkpSUpOTlZ+fr5mz56te++913eezea/ztuyrDP2XSw6MAAAGCaYHRi73a66dev6bWcrYOLi4nTdddf57bv22mu1d+9eSZLT6ZSkM7othYWFZ3RlLhYFDAAAhrFswdsC0alTJ3355Zd++3bu3KmmTZtKkhITE+V0OpWTk+M7XlZWprVr1yolJeWiP/fPESEBAIBKefjhh5WSkqLMzEz1799fn376qebMmaM5c+ZI+iE6SktLU2ZmppKSkpSUlKTMzExFRUVp0KBBQR0LBQwAAIa5kBvQBUP79u21ZMkSZWRk6Mknn1RiYqKys7M1ePBg3znjxo1TaWmpRo0apaKiInXo0EErV65UTExMUMdisyyrWjwTKiziF6EeAlCjlR74MNRDAGq08EbNq+y9Zib8PmjXevDb14N2rarEHBgAAGAcIiQAAAxTLaKTEKOAAQDAMN7g3lLFSERIAADAOHRgAAAwTKhWIVUnFDAAABiGAoYICQAAGIgODAAAhmEVEgUMAADGYRUSERIAADAQHRgAAAzDJF4KGAAAjMMcGCIkAABgIDowAAAYxksPhgIGAADTMAeGCAkAABiIDgwAAIYhQKKAAQDAOERIREgAAMBAdGAAADAMjxKggAEAwDgsoyZCAgAABqIDAwCAYei/UMAAAGAcViERIQEAAAPRgQEAwDBM4qWAAQDAOJQvREgAAMBAdGAAADAMk3gpYAAAMA5zYIiQAACAgejAAABgGPovFDAAABiHOTBESAAAwEB0YAAAMIxFiEQHBgAAmIcODAAAhmEODAUMAADG4T4wREgAAMBAdGAAADAM/RcKGAAAjEOERISEc7jl5g5aumSu9n6Tp5Nl+9Wnz61+x196cbpOlu332z768N8hGi1QvW3a8h+NHjdJ3foMVqtOvbR6Xa7f8edeel133PMHte/eTym33a37x2To8/wv/M7519vLNezBcerQ80616tRLJUeOVuVHAKoVChicVXR0lD7/fLv+lPaXs57z7rvv6xcJbXzb7X2GVOEIAXOUlp7Q1S2a68/poyo83izhF/pz+igtfnW2Xp31V8U7HXrg4cd1uOi/vnNOnPDo5g7t9Id7B1bRqFFdeYO4mYoICWf17ntr9O57a855jqesTN99d6iKRgSY65aO7XVLx/ZnPd47tZvf3+P+9Actfuc97fy6QL9ulyxJGjLgfyRJn27+/NINFEbgRnYXUMDs27dPs2fPVm5urtxut2w2mxwOh1JSUjRy5EglJCRcinGimurSuaMO7Nuq/xaXaN26DZowMUuHDv1fqIcFGK28vFz/enuFYupE6+oWzUM9HKBaCqiAWb9+vXr16qWEhASlpqYqNTVVlmWpsLBQS5cu1YwZM7RixQp16tTpnNfxeDzyeDx++yzLks1mC/wTIGTefW+NFi16R3v27lNisyaaPPlR5ax8Szd16KWysrJQDw8wzgcffaJHJz2rEyc8urJhA83Jfkb168WGeliohkyOfoIloALm4Ycf1v3336/p06ef9XhaWpo2btx4zuu4XC498cQTfvtsV9SRrVbdQIaDEPvXv5b5/jk//0ttytuq3bs+0W9/211Ll64I4cgAM9104w1aNPc5Ff23WP/773c1doJLC17IVsP69UI9NFQzREgBTuLdtm2bRo4cedbjI0aM0LZt2857nYyMDBUXF/tttitiAhkKqiG3u1B79uxXUovEUA8FMFJUZG01uSpeN7S6Vk9lPKxatWpp8b/fC/WwgGopoA5MXFyccnNzdfXVV1d4fMOGDYqLizvvdex2u+x2u98+4iPzNWhQXwkJcTroLgz1UIAawbIslZWXh3oYqIaIkAIsYMaOHauRI0cqLy9PPXv2lMPhkM1mk9vtVk5Ojl588UVlZ2dfoqGiqkVHR6nFz7opic2a6IYbWurw4SIdPvxfTZrwiBYvWa6D7u/UrGmCnn7qMX3/fRHxEVCB48dLtXffAd/f+w98py92fq3YujGKja2rOfMWqtvNHXRlowb6b/ERLVz8jr479L1u7XaL7zXf/99hff9/Rb7rfPX1N4qOilScs7Fi69LFvpx4LSIkm2UF9i28+eabmj59uvLy8nTq1ClJUq1atdS2bVulp6erf//+FzSQsIhfXNDrcOl06dxRq1f97xn75736lkY/mKHF//uS2rRppXr16urgwUJ9sDZXkyZP1b6f/Usa1UfpgQ9DPYTL2qebP9d9D40/Y3/fXj008dGHNG5ylv6z/UsVFRerXt26anXtr/TAsIFqfe1PHe/nXnpds1+ef8Y1nv5zuvr17nlJx4/zC29UdSvGhjS9M2jXem3P4qBdqyoFXMD8qLy8XN9//70kqVGjRgoPD7+ogVDAAJcWBQxwaVVlAfP7IBYwrxtawFzwjezCw8MrNd8FAAAEF89C4lECAADAQDxKAAAAw3AfGAoYAACMwzJqIiQAAHCBXC6XbDab0tLSfPssy9LkyZMVHx+vyMhIde3aVfn5+UF/bwoYAAAM45UVtO1Cbdy4UXPmzNH111/vt3/KlCmaNm2aZs6cqY0bN8rpdKpnz546cuTIxX5sPxQwAAAYxgri/zwej0pKSvy20x+4fLqjR49q8ODBeuGFF1S/fv2fxmVZys7O1uOPP64777xTrVq10rx583T8+HEtWLAgqN8BBQwAAJcxl8ul2NhYv83lcp3zNaNHj1bv3r3Vo0cPv/0FBQVyu91KTU317bPb7erSpYtyc3ODOm4m8QIAYJhgTuLNyMhQenq6377Tn1f4cwsXLlReXp42bdp0xjG32y1JcjgcfvsdDof27NkThNH+hAIGAADDXOBN9CtU0QOWz+bbb7/VmDFjtHLlStWuXfus553+gGbLsoL+0GYiJAAAUCl5eXkqLCxU27ZtFRYWprCwMK1du1b/+Mc/FBYW5uu8/NiJ+VFhYeEZXZmLRQEDAIBhQrUKqXv37vrPf/6jLVu2+LZ27dpp8ODB2rJli5o3by6n06mcnBzfa8rKyrR27VqlpKQE9TsgQgIAwDChupFdTEyMWrVq5bcvOjpaDRs29O1PS0tTZmamkpKSlJSUpMzMTEVFRWnQoEFBHQsFDAAACJpx48aptLRUo0aNUlFRkTp06KCVK1cqJiYmqO9js4I5E+gihEX8ItRDAGq00gMfhnoIQI0W3qh5lb3X7U16B+1a7+z9f0G7VlWiAwMAgGEu5g66NQWTeAEAgHHowAAAYJhqMvsjpChgAAAwTKhWIVUnREgAAMA4dGAAADCMxSReChgAAEzDKiQiJAAAYCA6MAAAGIZVSBQwAAAYhwiJCAkAABiIDgwAAIZhFRIFDAAAxvEyB4YICQAAmIcODAAAhqH/QgEDAIBxWIVEhAQAAAxEBwYAAMPQgaGAAQDAONyJlwgJAAAYiA4MAACGIUKigAEAwDjciZcICQAAGIgODAAAhmESLwUMAADGYQ4MERIAADAQHRgAAAxDhEQBAwCAcYiQiJAAAICB6MAAAGAY7gNDAQMAgHG8zIEhQgIAAOahAwMAgGGIkChgAAAwDhESERIAADAQHRgAAAxDhEQBAwCAcYiQiJAAAICB6MAAAGAYIiQKGAAAjEOERIQEAAAMRAcGAADDECFRwAAAYBzL8oZ6CCFHhAQAAIxDBwYAAMN4iZAoYAAAMI3FKiQiJAAAYB46MAAAGIYIiQIGAADjECERIQEAAAPRgQEAwDA8SoACBgAA43AnXiIkAABgIDowAAAYhkm8FDAAABiHZdRESAAAoJJcLpfat2+vmJgYNW7cWP369dOXX37pd45lWZo8ebLi4+MVGRmprl27Kj8/P+hjoYABAMAwlmUFbQvE2rVrNXr0aH388cfKycnRyZMnlZqaqmPHjvnOmTJliqZNm6aZM2dq48aNcjqd6tmzp44cORLU78BmVZMgLSziF6EeAlCjlR74MNRDAGq08EbNq+y9GsQkBe1ah498dcGvPXTokBo3bqy1a9eqc+fOsixL8fHxSktL0/jx4yVJHo9HDodDWVlZGjFiRLCGTQcGAIDLmcfjUUlJid/m8Xgq9dri4mJJUoMGDSRJBQUFcrvdSk1N9Z1jt9vVpUsX5ebmBnXcFDAAABgmmBGSy+VSbGys3+ZyuSo1hvT0dN18881q1aqVJMntdkuSHA6H37kOh8N3LFhYhQQAgGGCuQopIyND6enpfvvsdvt5X/fggw/q888/1/r16884ZrPZ/P62LOuMfReLAgYAgMuY3W6vVMHycw899JCWLVumdevW6aqrrvLtdzqdkn7oxMTFxfn2FxYWntGVuVhESAAAGCZUq5Asy9KDDz6oxYsX6/3331diYqLf8cTERDmdTuXk5Pj2lZWVae3atUpJSQnKZ/8RHRgAAAwTqoc5jh49WgsWLNDbb7+tmJgY37yW2NhYRUZGymazKS0tTZmZmUpKSlJSUpIyMzMVFRWlQYMGBXUsLKMGLhMsowYurapcRl0nKvH8J1XS0eMFlT73bPNYXnnlFQ0bNkzSD12aJ554Qs8//7yKiorUoUMHPffcc76JvsFCAQNcJihggEurKguY6KhmQbvWsePfBO1aVYkICQAAw4QqQqpOmMQLAACMQwcGAADDVJPZHyFFAQMAgGGsIN7IzlRESAAAwDh0YAAAMAwREgUMAADGoYAhQgIAAAaiAwMAgGHov1SjO/HCHB6PRy6XSxkZGQE/wRTA+fEbA86PAgYBKykpUWxsrIqLi1W3bt1QDweocfiNAefHHBgAAGAcChgAAGAcChgAAGAcChgEzG63a9KkSUwuBC4RfmPA+TGJFwAAGIcODAAAMA4FDAAAMA4FDAAAMA4FDAAAMA4FDAI2efJktWnTxvf3sGHD1K9fv5CNB6hp+I0B50cBU4MMGzZMNptNNptN4eHhat68ucaOHatjx45d0vf9+9//rrlz51bq3G+++UY2m01btmzx25+fn6/f/e53atasmWw2m7Kzs4M+TuBimfwbk6RFixbpuuuuk91u13XXXaclS5YEd6BAFaKAqWFuu+02HTx4ULt379bTTz+tWbNmaezYsWecV15eHrT3jI2NVb169S7qGsePH1fz5s317LPPyul0BmdgwCVg6m9sw4YNGjBggIYMGaKtW7dqyJAh6t+/vz755JPgDBKoYhQwNYzdbpfT6VRCQoIGDRqkwYMHa+nSpb6W9Msvv6zmzZvLbrfLsiwVFxfrgQceUOPGjVW3bl395je/0datW/2u+eyzz8rhcCgmJkbDhw/XiRMn/I6f3t72er3KyspSixYtZLfb1aRJEz3zzDOSpMTERElScnKybDabunbtKklq3769pk6dqoEDB3LzLlRrpv7GsrOz1bNnT2VkZOiaa65RRkaGunfvTrcTxqKAqeEiIyN9/yW4a9cuvfXWW1q0aJGvvdy7d2+53W4tX75ceXl5uvHGG9W9e3cdPnxYkvTWW29p0qRJeuaZZ7Rp0ybFxcVp1qxZ53zPjIwMZWVlacKECdq+fbsWLFggh8MhSfr0008lSatWrdLBgwe1ePHiS/TJgaphym9sw4YNSk1N9bvOrbfeqtzc3KB9F0CVslBjDB061Orbt6/v708++cRq2LCh1b9/f2vSpElWeHi4VVhY6Du+evVqq27dutaJEyf8rvPLX/7Sev755y3LsqyOHTtaI0eO9DveoUMH64YbbqjwfUtKSiy73W698MILFY6xoKDAkmR99tlnZ/0cTZs2taZPn37+DwxUMZN/Y+Hh4db8+fP99s2fP9+KiIiozEcHqh06MDXMO++8ozp16qh27drq2LGjOnfurBkzZkiSmjZtqiuvvNJ3bl5eno4ePaqGDRuqTp06vq2goEBff/21JGnHjh3q2LGj33uc/vfP7dixQx6PR927d78Enw4IPZN/Yzabze9vy7LO2AeYIizUA0BwdevWTbNnz1Z4eLji4+MVHh7uOxYdHe13rtfrVVxcnD744IMzrnOhEwYjIyMv6HWAKUz9jTmdTrndbr99hYWFvugJMA0dmBomOjpaLVq0UNOmTf3+xVqRG2+8UW63W2FhYWrRooXf1qhRI0nStddeq48//tjvdaf//XNJSUmKjIzU6tWrKzweEREhSTp16lQgHwuoNkz9jXXs2FE5OTl++1auXKmUlJRzfgaguqIDcxnr0aOHOnbsqH79+ikrK0tXX321Dhw4oOXLl6tfv35q166dxowZo6FDh6pdu3a6+eabNX/+fOXn56t58+YVXrN27doaP368xo0bp4iICHXq1EmHDh1Sfn6+hg8frsaNGysyMlLvvvuurrrqKtWuXVuxsbEqKyvT9u3bJUllZWXav3+/tmzZojp16qhFixZV+bUAQVOdfmNjxoxR586dlZWVpb59++rtt9/WqlWrtH79+ir+VoDgoANzGbPZbFq+fLk6d+6s++67T7/61a80cOBAffPNN7628oABAzRx4kSNHz9ebdu21Z49e/THP/7xnNedMGGCHnnkEU2cOFHXXnutBgwYoMLCQklSWFiY/vGPf+j5559XfHy8+vbtK0k6cOCAkpOTlZycrIMHD+qvf/2rkpOTdf/991/aLwG4hKrTbywlJUULFy7UK6+8ouuvv15z587Vm2++qQ4dOlzaLwG4RGyWZVmhHgQAAEAg6MAAAADjUMAAAADjUMAAAADjUMAAAADjUMAAAADjUMAAAADjUMAAAADjUMAAAADjUMAAAADjUMAAAADjUMAAAADj/H+yMi0o4xW2jgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 700x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm=metrics.confusion_matrix(Y_test,predictions,labels=[1,0])\n",
    "df_cm=pd.DataFrame(cm,index=[i for i in [\"1\",\"0\"]],\n",
    "                   columns=[i for i in [\"Predict1\",\"Predict0\"]])\n",
    "plt.figure(figsize=(7,5))\n",
    "sns.heatmap(df_cm,annot=True,fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a40e6fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 48,  37],\n",
       "       [ 15, 131]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01267b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predict1</th>\n",
       "      <th>Predict0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predict1  Predict0\n",
       "1        48        37\n",
       "0        15       131"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd17c3",
   "metadata": {},
   "source": [
    "# Support Vector Classifier Algorithm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7599dcd5",
   "metadata": {},
   "source": [
    "with structured as well as instructured, time consuming, try to find the right hyperplane with maximum margin\n",
    "Classification done by find the right hyperplane to separate both tthe classes with large(maximum) margin\n",
    "Difference between parameters and hyper parameters, also ypu should know in each algo what are parameters and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3537c6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d643df1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7653631284916201"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "09be8e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7705627705627706"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87dca986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf')\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd1a7cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7560521415270018"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f793d9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7662337662337663"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f078c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='poly')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='poly')\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d0e98be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7579143389199255"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8049cd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792207792207793"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36f8859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(kernel='sigmoid')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='sigmoid')\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e647947b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4171322160148976"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72b2dd91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3722943722943723"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80d88bb1",
   "metadata": {},
   "source": [
    "kernel linear seems to give the best score\n",
    "precomputed kernel can't be used as it requires square matrix\n",
    "now check with different values of C(it is penalty i.e how many misclassifications are allowed), kernel and gamma=(auto or scale) to get the best score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "edfcaedd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=3, kernel='linear')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=3, gamma='scale')\n",
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5fbfa8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7635009310986964"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "228522d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7748917748917749"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a720698",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b2ed52ad",
   "metadata": {},
   "source": [
    "K nearest neighbour\n",
    "Pass the value k\n",
    "for a test data point, calculates distance from all other data points and sorts in ascending order, now take the top k distances and find they belong to which class, majority no. decides the class of the test data point.\n",
    "Keep the k value odd preferably\n",
    "distance : 1. Euclidean(normal geometric distance)  2. Manhattan(sum of absolute coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0a452fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7a6cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=5, weights='uniform',p=1)#p=1 means manhattan, p=2 means euclidean , bracket terms are hyperparamteters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9a33b631",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(p=1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fe2fc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8100558659217877"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dac20f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7705627705627706"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9154f4b4",
   "metadata": {},
   "source": [
    "# Decision Tree ensemble"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d17f5570",
   "metadata": {},
   "source": [
    "at each node yes or no condition and further node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "83698083",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3b802bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=5)\n",
    "tree.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a99c72db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8379888268156425"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3488d0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7835497835497836"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6f4276c",
   "metadata": {},
   "source": [
    "Now tweak the hyperparameters\n",
    "ginni and entropy\n",
    "max_depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546efe4a",
   "metadata": {},
   "source": [
    "# Ensemble Learning - Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bbf8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e8a1a36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py:719: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=5),\n",
       "                  max_samples=100, n_estimators=100, random_state=1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgcl = BaggingClassifier(n_estimators=100,base_estimator = tree, max_samples=100,random_state=1)\n",
    "bgcl.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "36d9aa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8175046554934823"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgcl.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "768f44c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7965367965367965"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgcl.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758a5d1b",
   "metadata": {},
   "source": [
    "# Ensemble Learning - AdaBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6dc10035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9f5b749f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.7, n_estimators=100, random_state=1)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abcl = AdaBoostClassifier(n_estimators=100,learning_rate=0.7,random_state=1)\n",
    "abcl.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "20a4b8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8472998137802608 0.8051948051948052\n"
     ]
    }
   ],
   "source": [
    "print(abcl.score(X_train,Y_train), abcl.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff81aa8",
   "metadata": {},
   "source": [
    "# Ensemble Learning - GradientBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "13e0f4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "32d2f9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=2, max_features=7, n_estimators=40,\n",
       "                           random_state=1)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbcl = GradientBoostingClassifier(learning_rate=0.1,n_estimators=40,max_depth=2,max_features=7,random_state=1)\n",
    "gbcl.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b17650d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819366852886406 0.7792207792207793\n"
     ]
    }
   ],
   "source": [
    "print(gbcl.score(X_train,Y_train), gbcl.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba87d51",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e374ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "16fd83c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priyanshu\\AppData\\Local\\Temp\\ipykernel_5920\\2866524272.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  rfcl.fit(X_train,Y_train)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', min_samples_split=50,\n",
       "                       n_estimators=500)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcl = RandomForestClassifier(n_estimators=500,criterion='entropy', min_samples_split=50)\n",
    "rfcl.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fca34ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8305400372439479 0.7878787878787878\n"
     ]
    }
   ],
   "source": [
    "print(rfcl.score(X_train,Y_train), rfcl.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bb7371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d86fc42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
